{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from utils_mnist import (\n",
    "    test,\n",
    "    visualize_gen_image,\n",
    "    visualize_gmm_latent_representation,\n",
    "    non_iid_train_iid_test_6789,\n",
    "    subset_alignment_dataloader,\n",
    "    train_align,\n",
    "    eval_reconstrution,\n",
    ")\n",
    "from utils_mnist import VAE\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_mnist import VAE\n",
    "\n",
    "NUM_CLIENTS = 2\n",
    "NUM_CLASSES = 4\n",
    "samples_per_class = 200\n",
    "alignment_dataloader = subset_alignment_dataloader(\n",
    "    samples_per_class=samples_per_class,\n",
    "    batch_size=samples_per_class * NUM_CLASSES,\n",
    ")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_img, img, mu, logvar):\n",
    "    # Reconstruction loss using binary cross-entropy\n",
    "    condition = (recon_img >= 0.0) & (recon_img <= 1.0)\n",
    "    # assert torch.all(condition), \"Values should be between 0 and 1\"\n",
    "    # if not torch.all(condition):\n",
    "    #     ValueError(\"Values should be between 0 and 1\")\n",
    "    #     recon_img = torch.clamp(recon_img, 0.0, 1.0)\n",
    "    recon_loss = F.binary_cross_entropy(\n",
    "        recon_img, img.view(-1, img.shape[2] * img.shape[3]), reduction=\"sum\"\n",
    "    )\n",
    "    # KL divergence loss\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Total VAE loss\n",
    "    total_loss = recon_loss + kld_loss*5\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayag88/mayag88/miniconda3/envs/py38/lib/python3.8/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 434872.9375\n",
      "--------------------------------------------------\n",
      "Epoch 100, Loss 146453.640625\n",
      "--------------------------------------------------\n",
      "Epoch 200, Loss 139193.765625\n",
      "--------------------------------------------------\n",
      "Epoch 300, Loss 131410.9375\n",
      "--------------------------------------------------\n",
      "Epoch 400, Loss 128147.421875\n",
      "--------------------------------------------------\n",
      "Epoch 500, Loss 124872.140625\n",
      "--------------------------------------------------\n",
      "Epoch 600, Loss 123540.96875\n",
      "--------------------------------------------------\n",
      "Epoch 700, Loss 121272.7265625\n",
      "--------------------------------------------------\n",
      "Epoch 800, Loss 120235.328125\n",
      "--------------------------------------------------\n",
      "Epoch 900, Loss 119476.59375\n",
      "--------------------------------------------------\n",
      "Epoch 1000, Loss 118929.9375\n",
      "--------------------------------------------------\n",
      "Epoch 1100, Loss 118031.484375\n",
      "--------------------------------------------------\n",
      "Epoch 1200, Loss 117590.2421875\n",
      "--------------------------------------------------\n",
      "Epoch 1300, Loss 117399.203125\n",
      "--------------------------------------------------\n",
      "Epoch 1400, Loss 116522.53125\n",
      "--------------------------------------------------\n",
      "Epoch 1500, Loss 115882.0625\n",
      "--------------------------------------------------\n",
      "Epoch 1600, Loss 115559.09375\n",
      "--------------------------------------------------\n",
      "Epoch 1700, Loss 114847.84375\n",
      "--------------------------------------------------\n",
      "Epoch 1800, Loss 114855.734375\n",
      "--------------------------------------------------\n",
      "Epoch 1900, Loss 114015.4453125\n",
      "--------------------------------------------------\n",
      "Epoch 2000, Loss 113575.234375\n",
      "--------------------------------------------------\n",
      "Epoch 2100, Loss 112947.34375\n",
      "--------------------------------------------------\n",
      "Epoch 2200, Loss 113019.765625\n",
      "--------------------------------------------------\n",
      "Epoch 2300, Loss 112541.7421875\n",
      "--------------------------------------------------\n",
      "Epoch 2400, Loss 112356.078125\n",
      "--------------------------------------------------\n",
      "Epoch 2500, Loss 111606.171875\n",
      "--------------------------------------------------\n",
      "Epoch 2600, Loss 111782.78125\n",
      "--------------------------------------------------\n",
      "Epoch 2700, Loss 111124.4765625\n",
      "--------------------------------------------------\n",
      "Epoch 2800, Loss 111036.875\n",
      "--------------------------------------------------\n",
      "Epoch 2900, Loss 110275.0390625\n",
      "--------------------------------------------------\n",
      "Epoch 3000, Loss 110301.375\n",
      "--------------------------------------------------\n",
      "Epoch 3100, Loss 109740.484375\n",
      "--------------------------------------------------\n",
      "Epoch 3200, Loss 109566.7578125\n",
      "--------------------------------------------------\n",
      "Epoch 3300, Loss 109257.375\n",
      "--------------------------------------------------\n",
      "Epoch 3400, Loss 108627.2109375\n",
      "--------------------------------------------------\n",
      "Epoch 3500, Loss 108605.5625\n",
      "--------------------------------------------------\n",
      "Epoch 3600, Loss 109167.078125\n",
      "--------------------------------------------------\n",
      "Epoch 3700, Loss 108243.6640625\n",
      "--------------------------------------------------\n",
      "Epoch 3800, Loss 107958.359375\n",
      "--------------------------------------------------\n",
      "Epoch 3900, Loss 107482.140625\n",
      "--------------------------------------------------\n",
      "Epoch 4000, Loss 107461.2578125\n",
      "--------------------------------------------------\n",
      "Epoch 4100, Loss 107073.984375\n",
      "--------------------------------------------------\n",
      "Epoch 4200, Loss 107320.140625\n",
      "--------------------------------------------------\n",
      "Epoch 4300, Loss 106419.59375\n",
      "--------------------------------------------------\n",
      "Epoch 4400, Loss 105962.6328125\n",
      "--------------------------------------------------\n",
      "Epoch 4500, Loss 106292.2265625\n",
      "--------------------------------------------------\n",
      "Epoch 4600, Loss 106007.421875\n",
      "--------------------------------------------------\n",
      "Epoch 4700, Loss 105793.921875\n",
      "--------------------------------------------------\n",
      "Epoch 4800, Loss 105288.8046875\n",
      "--------------------------------------------------\n",
      "Epoch 4900, Loss 105317.78125\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ref_model = VAE(z_dim=2).to(DEVICE)\n",
    "opt_ref = torch.optim.Adam(ref_model.parameters(), lr=1e-3)\n",
    "for ep in range(5000):\n",
    "    for images, _ in alignment_dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        opt_ref.zero_grad()\n",
    "        recon_images, mu, logvar = ref_model(images)\n",
    "        vae_loss1 = vae_loss(recon_images, images, mu, logvar)\n",
    "        vae_loss1.backward()\n",
    "        opt_ref.step()\n",
    "        \n",
    "    if ep % 100 == 0:\n",
    "        print(f\"Epoch {ep}, Loss {vae_loss1.item()}\")\n",
    "    \n",
    "        print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VAE on test set\n",
    "ref_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_latents = []\n",
    "    test_labels = []  # Store corresponding labels\n",
    "    for x, labels in alignment_dataloader:  # Retrieve labels from test_loader\n",
    "        x = x.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        recon_images, mu, logvar = ref_model(x)\n",
    "        test_latents.append(mu.cpu().numpy())\n",
    "        test_labels.append(labels.cpu().numpy())  # Store labels\n",
    "\n",
    "# Visualize latent representations in 2D\n",
    "test_latents = np.concatenate(test_latents, axis=0)\n",
    "test_labels = np.concatenate(test_labels, axis=0)  # Concatenate all labels\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming test_latents is a numpy array with shape (num_samples, 16)\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "test_latents_pca = pca.fit_transform(test_latents)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in np.unique(test_labels):\n",
    "    indices = np.where(test_labels == label)\n",
    "    # print(indices)\n",
    "    # print(indices[0])  # Use [0] to access indices\n",
    "    plt.scatter(\n",
    "        test_latents[indices, 0],\n",
    "        test_latents[indices, 1],\n",
    "        label=label,\n",
    "        alpha=1,\n",
    "    )\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "plt.title(\"Latent Space Visualization of Test Set with Class Highlight\")\n",
    "plt.legend()\n",
    "plt.savefig(\"latent_space_visualization.png\")  # Save the figure as PNG\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
