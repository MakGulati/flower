{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from utils_mnist import (\n",
    "    test,\n",
    "    visualize_gen_image,\n",
    "    visualize_gmm_latent_representation,\n",
    "    non_iid_train_iid_test_6789,\n",
    "    subset_alignment_dataloader,\n",
    "    train_align,\n",
    "    eval_reconstrution,\n",
    ")\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_mnist import VAE\n",
    "\n",
    "NUM_CLIENTS = 2\n",
    "NUM_CLASSES = 4\n",
    "samples_per_class = 200\n",
    "alignment_dataloader = subset_alignment_dataloader(\n",
    "    samples_per_class=samples_per_class,\n",
    "    batch_size=samples_per_class * NUM_CLASSES,\n",
    ")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self, x_dim=784, h_dim1=512, h_dim2=256, h_dim3=128, z_dim=10, num_classes=10\n",
    "    ):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Encoder part\n",
    "        self.fc1 = nn.Linear(x_dim + self.num_classes, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc3 = nn.Linear(h_dim2, h_dim3)\n",
    "        self.fc41 = nn.Linear(h_dim3, z_dim)  # mu\n",
    "        self.fc42 = nn.Linear(h_dim3, z_dim)  # log_var\n",
    "\n",
    "        # Decoder part\n",
    "        self.label_projection = nn.Linear(num_classes, z_dim)\n",
    "        self.fc5 = nn.Linear(z_dim, h_dim3)\n",
    "        self.fc6 = nn.Linear(h_dim3, h_dim2)\n",
    "        self.fc7 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc8 = nn.Linear(h_dim1, x_dim)\n",
    "\n",
    "    def encoder(self, x, y):\n",
    "        input_cat = torch.cat((x, y), dim=1)\n",
    "        h = F.relu(self.fc1(input_cat))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = F.relu(self.fc3(h))\n",
    "        return self.fc41(h), self.fc42(h)  # mu, log_var\n",
    "\n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)  # return z sample\n",
    "\n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc5(z))\n",
    "        h = F.relu(self.fc6(h))\n",
    "        h = F.relu(self.fc7(h))\n",
    "        return torch.sigmoid(self.fc8(h))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        y_onehot = F.one_hot(y, self.num_classes).float()\n",
    "        mu, log_var = self.encoder(x.view(-1, 784), y_onehot)\n",
    "        z = self.sampling(mu, log_var)\n",
    "\n",
    "        # Project one-hot encoded conditional information to latent space\n",
    "        y_proj = self.label_projection(y_onehot)\n",
    "\n",
    "        # Combine latent vector z with projected conditional information y\n",
    "        z_combined = z + y_proj\n",
    "\n",
    "        output = self.decoder(z_combined)\n",
    "        return output, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_img, img, mu, logvar):\n",
    "    # Reconstruction loss using binary cross-entropy\n",
    "    condition = (recon_img >= 0.0) & (recon_img <= 1.0)\n",
    "    # assert torch.all(condition), \"Values should be between 0 and 1\"\n",
    "    # if not torch.all(condition):\n",
    "    #     ValueError(\"Values should be between 0 and 1\")\n",
    "    #     recon_img = torch.clamp(recon_img, 0.0, 1.0)\n",
    "    recon_loss = F.binary_cross_entropy(recon_img, img.view(-1, 784), reduction='sum')\n",
    "    # KL divergence loss\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Total VAE loss\n",
    "    total_loss = recon_loss + kld_loss*0.01\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 434892.8125\n",
      "--------------------------------------------------\n",
      "Epoch 100, Loss 134671.4375\n",
      "--------------------------------------------------\n",
      "Epoch 200, Loss 112528.421875\n",
      "--------------------------------------------------\n",
      "Epoch 300, Loss 105083.7265625\n",
      "--------------------------------------------------\n",
      "Epoch 400, Loss 101315.2265625\n",
      "--------------------------------------------------\n",
      "Epoch 500, Loss 98174.7734375\n",
      "--------------------------------------------------\n",
      "Epoch 600, Loss 95701.7421875\n",
      "--------------------------------------------------\n",
      "Epoch 700, Loss 94276.34375\n",
      "--------------------------------------------------\n",
      "Epoch 800, Loss 92183.3203125\n",
      "--------------------------------------------------\n",
      "Epoch 900, Loss 90803.0234375\n",
      "--------------------------------------------------\n",
      "Epoch 1000, Loss 89651.8515625\n",
      "--------------------------------------------------\n",
      "Epoch 1100, Loss 88031.140625\n",
      "--------------------------------------------------\n",
      "Epoch 1200, Loss 87063.4921875\n",
      "--------------------------------------------------\n",
      "Epoch 1300, Loss 85810.3515625\n",
      "--------------------------------------------------\n",
      "Epoch 1400, Loss 84425.8046875\n",
      "--------------------------------------------------\n",
      "Epoch 1500, Loss 83622.40625\n",
      "--------------------------------------------------\n",
      "Epoch 1600, Loss 82783.46875\n",
      "--------------------------------------------------\n",
      "Epoch 1700, Loss 82216.203125\n",
      "--------------------------------------------------\n",
      "Epoch 1800, Loss 81707.03125\n",
      "--------------------------------------------------\n",
      "Epoch 1900, Loss 80770.7421875\n",
      "--------------------------------------------------\n",
      "Epoch 2000, Loss 80703.3359375\n",
      "--------------------------------------------------\n",
      "Epoch 2100, Loss 79585.6484375\n",
      "--------------------------------------------------\n",
      "Epoch 2200, Loss 79606.7265625\n",
      "--------------------------------------------------\n",
      "Epoch 2300, Loss 79350.1640625\n",
      "--------------------------------------------------\n",
      "Epoch 2400, Loss 77854.9140625\n",
      "--------------------------------------------------\n",
      "Epoch 2500, Loss 78080.9921875\n",
      "--------------------------------------------------\n",
      "Epoch 2600, Loss 77791.6953125\n",
      "--------------------------------------------------\n",
      "Epoch 2700, Loss 77413.4609375\n",
      "--------------------------------------------------\n",
      "Epoch 2800, Loss 77144.1328125\n",
      "--------------------------------------------------\n",
      "Epoch 2900, Loss 75971.1015625\n",
      "--------------------------------------------------\n",
      "Epoch 3000, Loss 75343.578125\n",
      "--------------------------------------------------\n",
      "Epoch 3100, Loss 75070.2734375\n",
      "--------------------------------------------------\n",
      "Epoch 3200, Loss 75053.2265625\n",
      "--------------------------------------------------\n",
      "Epoch 3300, Loss 74433.6953125\n",
      "--------------------------------------------------\n",
      "Epoch 3400, Loss 73921.46875\n",
      "--------------------------------------------------\n",
      "Epoch 3500, Loss 74781.0703125\n",
      "--------------------------------------------------\n",
      "Epoch 3600, Loss 73356.59375\n",
      "--------------------------------------------------\n",
      "Epoch 3700, Loss 73664.5234375\n",
      "--------------------------------------------------\n",
      "Epoch 3800, Loss 72933.625\n",
      "--------------------------------------------------\n",
      "Epoch 3900, Loss 73165.0234375\n",
      "--------------------------------------------------\n",
      "Epoch 4000, Loss 72916.9296875\n",
      "--------------------------------------------------\n",
      "Epoch 4100, Loss 72674.2265625\n",
      "--------------------------------------------------\n",
      "Epoch 4200, Loss 72546.90625\n",
      "--------------------------------------------------\n",
      "Epoch 4300, Loss 71698.2109375\n",
      "--------------------------------------------------\n",
      "Epoch 4400, Loss 71383.375\n",
      "--------------------------------------------------\n",
      "Epoch 4500, Loss 71030.15625\n",
      "--------------------------------------------------\n",
      "Epoch 4600, Loss 70840.609375\n",
      "--------------------------------------------------\n",
      "Epoch 4700, Loss 71496.03125\n",
      "--------------------------------------------------\n",
      "Epoch 4800, Loss 70400.296875\n",
      "--------------------------------------------------\n",
      "Epoch 4900, Loss 70762.0625\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ref_model = CVAE(z_dim=2).to(DEVICE)\n",
    "opt_ref = torch.optim.Adam(ref_model.parameters(), lr=1e-3)\n",
    "for ep in range(5000):\n",
    "    for images, labels in alignment_dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        opt_ref.zero_grad()\n",
    "        recon_images, mu, logvar = ref_model(images, labels)\n",
    "        vae_loss1 = vae_loss(recon_images, images, mu, logvar)\n",
    "        vae_loss1.backward()\n",
    "        opt_ref.step()\n",
    "        \n",
    "    if ep % 100 == 0:\n",
    "        print(f\"Epoch {ep}, Loss {vae_loss1.item()}\")\n",
    "    \n",
    "        print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 70338.3203125\n",
      "--------------------------------------------------\n",
      "Epoch 100, Loss 70393.8046875\n",
      "--------------------------------------------------\n",
      "Epoch 200, Loss 70176.6796875\n",
      "--------------------------------------------------\n",
      "Epoch 300, Loss 70327.703125\n",
      "--------------------------------------------------\n",
      "Epoch 400, Loss 69082.7265625\n",
      "--------------------------------------------------\n",
      "Epoch 500, Loss 69001.875\n",
      "--------------------------------------------------\n",
      "Epoch 600, Loss 68813.0625\n",
      "--------------------------------------------------\n",
      "Epoch 700, Loss 69031.7578125\n",
      "--------------------------------------------------\n",
      "Epoch 800, Loss 68271.25\n",
      "--------------------------------------------------\n",
      "Epoch 900, Loss 68457.6328125\n",
      "--------------------------------------------------\n",
      "Epoch 1000, Loss 68207.9453125\n",
      "--------------------------------------------------\n",
      "Epoch 1100, Loss 68065.2265625\n",
      "--------------------------------------------------\n",
      "Epoch 1200, Loss 68406.3125\n",
      "--------------------------------------------------\n",
      "Epoch 1300, Loss 69576.6171875\n",
      "--------------------------------------------------\n",
      "Epoch 1400, Loss 68202.6171875\n",
      "--------------------------------------------------\n",
      "Epoch 1500, Loss 68412.5078125\n",
      "--------------------------------------------------\n",
      "Epoch 1600, Loss 67670.03125\n",
      "--------------------------------------------------\n",
      "Epoch 1700, Loss 67201.5546875\n",
      "--------------------------------------------------\n",
      "Epoch 1800, Loss 67528.296875\n",
      "--------------------------------------------------\n",
      "Epoch 1900, Loss 66513.40625\n",
      "--------------------------------------------------\n",
      "Epoch 2000, Loss 66656.4453125\n",
      "--------------------------------------------------\n",
      "Epoch 2100, Loss 67077.3515625\n",
      "--------------------------------------------------\n",
      "Epoch 2200, Loss 66752.0625\n",
      "--------------------------------------------------\n",
      "Epoch 2300, Loss 66366.2578125\n",
      "--------------------------------------------------\n",
      "Epoch 2400, Loss 66597.375\n",
      "--------------------------------------------------\n",
      "Epoch 2500, Loss 66118.8046875\n",
      "--------------------------------------------------\n",
      "Epoch 2600, Loss 67474.875\n",
      "--------------------------------------------------\n",
      "Epoch 2700, Loss 66478.1015625\n",
      "--------------------------------------------------\n",
      "Epoch 2800, Loss 65356.08984375\n",
      "--------------------------------------------------\n",
      "Epoch 2900, Loss 65814.75\n",
      "--------------------------------------------------\n",
      "Epoch 3000, Loss 64915.65625\n",
      "--------------------------------------------------\n",
      "Epoch 3100, Loss 64702.76953125\n",
      "--------------------------------------------------\n",
      "Epoch 3200, Loss 65470.46875\n",
      "--------------------------------------------------\n",
      "Epoch 3300, Loss 64664.16796875\n",
      "--------------------------------------------------\n",
      "Epoch 3400, Loss 64589.05859375\n",
      "--------------------------------------------------\n",
      "Epoch 3500, Loss 64239.44140625\n",
      "--------------------------------------------------\n",
      "Epoch 3600, Loss 64975.4296875\n",
      "--------------------------------------------------\n",
      "Epoch 3700, Loss 64574.2578125\n",
      "--------------------------------------------------\n",
      "Epoch 3800, Loss 64297.1796875\n",
      "--------------------------------------------------\n",
      "Epoch 3900, Loss 64439.71484375\n",
      "--------------------------------------------------\n",
      "Epoch 4000, Loss 64451.37109375\n",
      "--------------------------------------------------\n",
      "Epoch 4100, Loss 64148.25390625\n",
      "--------------------------------------------------\n",
      "Epoch 4200, Loss 64360.4609375\n",
      "--------------------------------------------------\n",
      "Epoch 4300, Loss 64037.85546875\n",
      "--------------------------------------------------\n",
      "Epoch 4400, Loss 64481.6796875\n",
      "--------------------------------------------------\n",
      "Epoch 4500, Loss 63509.484375\n",
      "--------------------------------------------------\n",
      "Epoch 4600, Loss 63026.33984375\n",
      "--------------------------------------------------\n",
      "Epoch 4700, Loss 63772.2265625\n",
      "--------------------------------------------------\n",
      "Epoch 4800, Loss 63929.61328125\n",
      "--------------------------------------------------\n",
      "Epoch 4900, Loss 63218.5625\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ep in range(5000):\n",
    "    for images, labels in alignment_dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        opt_ref.zero_grad()\n",
    "        recon_images, mu, logvar = ref_model(images, labels)\n",
    "        vae_loss1 = vae_loss(recon_images, images, mu, logvar)\n",
    "        vae_loss1.backward()\n",
    "        opt_ref.step()\n",
    "\n",
    "    if ep % 100 == 0:\n",
    "        print(f\"Epoch {ep}, Loss {vae_loss1.item()}\")\n",
    "\n",
    "        print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VAE on test set\n",
    "ref_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_latents = []\n",
    "    test_labels = []  # Store corresponding labels\n",
    "    for x, labels in alignment_dataloader:  # Retrieve labels from test_loader\n",
    "        x = x.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        recon_images, mu, logvar = ref_model(x, labels)\n",
    "        test_latents.append(mu.cpu().numpy())\n",
    "        test_labels.append(labels.cpu().numpy())  # Store labels\n",
    "\n",
    "# Visualize latent representations in 2D\n",
    "test_latents = np.concatenate(test_latents, axis=0)\n",
    "test_labels = np.concatenate(test_labels, axis=0)  # Concatenate all labels\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming test_latents is a numpy array with shape (num_samples, 16)\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "test_latents_pca = pca.fit_transform(test_latents)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in np.unique(test_labels):\n",
    "    indices = np.where(test_labels == label)\n",
    "    # print(indices)\n",
    "    # print(indices[0])  # Use [0] to access indices\n",
    "    plt.scatter(\n",
    "        test_latents[indices, 0],\n",
    "        test_latents[indices, 1],\n",
    "        label=label,\n",
    "        alpha=1,\n",
    "    )\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "plt.title(\"Latent Space Visualization of Test Set with Class Highlight\")\n",
    "plt.legend()\n",
    "plt.savefig(\"latent_space_visualization.png\")  # Save the figure as PNG\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
